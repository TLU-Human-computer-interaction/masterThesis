% !TeX root = thesis.tex
\documentclass{master_thesis}
\addbibresource{refs.bib}

\begin{document}

\subsection{Web accessibility}

Accessibility is about providing equal access to goods and services to everyone regardless of age, gender or disabilities. We all have different abilities, some run faster than others, some see more clearly and some might not be able to hear sounds. WHO estimates that 1.3 billion people – or about 16\% of the global population – experience a significant disability and this number is growing \citep{WHO2022}. Disability is a part of being human and persons with disabilities are different from each other. We can also talk about temporary disability - this might be a mother who can only use one hand because she is holding a child in the other or someone who broke an arm and can't use it until it heals. The limited ability might be very similar to someone who has a permanent condition. Everyone who designs the physical and virtual environment around us should consider these different limitations.

Accessibility principles can be applied to various fields. For example, in architecture, it could be designing buildings in a way that can be accessed by people who can walk on their own as well as the ones who need to use a wheelchair. In digital products it is more often related to the senses we use to consume content. Everything could be equally accessible whether I need or want to consume the information using my vision or ability to hear.

The biggest strength of the web is how easily available it is to everyone. Tim Berners-Lee, W3C Director and inventor of the World Wide Web said: "The power of the Web is in its universality. Access by everyone regardless of disability is an essential aspect" \citep{WWWC1997}. The virtual world has the potential to be much more inclusive than the physical world.

Web accessibility considers auditory, cognitive, neurological, physical, speech and visual disabilities - everything that might affect someone's ability to access the Web and people using different devices, who have reduced abilities because of aging, temporary disabilities, situational limitations or are using limited or slow internet \citep{Henry2022}.

\subsubsection{Standards}

The standards for considering people with different abilities and making web content accessible for different ways of consuming are defined in Web Content Accessibility Guidelines (WCAG) \citep{Kirkpatrick2018}. The guidelines are developed by Web Accessibility Initiative (WAI) which is part of World Wide Web Consortium (W3C). 

First version of WCAG (1.0) was published in 1998 \citep{Vanderheiden2023}. The current version is WCAG 2.1 and the next version 2.2 is scheduled to be finalized in May 2023 \citep{Henry2023}. All WCAG versions are backward compatible, meaning that all requirements that were in 2.0 are included in 2.1 and some new requirements are added. Version 2.2 in currently in draft stage, but the planned changes include some changes to the current guidelines. One current requirement will be removed and another one will change from level AA to level A. 

WAI gives an overview of the laws and policies around the world. 25 out of 40 listed on the page are based on WCAG 2.0 or WCAG 2.0 derivative \citep{Mueller2018}. Pipedrive operates in the US and European markets so the most notable and relevant ones for me are the accessibility standard in European Union EN 301 549 enforced by Web and Mobile Accessibility Directive \citep{MuellerEU2017} and Section 508 of the US Rehabilitation Act of 1973, as amended in the United States \citep{MuellerUS2017}. WCAG 2.0 AA level conformance has been incorporated into the law in the US and the European standards' latest version follows WCAG 2.1 AA \citep{LevelAccess2021}. In this thesis, I will test against WCAG 2.1, because it is the latest published version of the most widely used standard.

\todo{What would be a better resource for this overview? This seems to be outdated because another resource said the EU standard is referencing WCAG 2.1}

WCAG is intended for developers of web content, authoring tools or web accessibility evaluation tools and others who need a standard for accessibility. The 4 principles of accessibility addressed in the guidelines are:
\begin{enumerate}
	\item Perceivable - information and user interface can't be invisible to all the user's senses,
	\item Operable - user can interact with the interface,
	\item Understandable - user should understand the information and how the user interface operates
	\item Robust - content should be robust enough that it can be interpreted reliably by a wide variety of user agents.
\end{enumerate}
Under each principle is a list of guidelines that address that principle \citep{AGWGWP2022}. Under each guideline, there are Success Criteria that describe specifically what conformance to it means. Each Success Criterion is a statement that will be either true or false for specific Web content.

\subsubsection{Rules format}

W3C Accessibility Guidelines Working Group has developed Accessibility Conformance Testing (ACT) Rules Format to provide developers of evaluation methodologies and testing tools a consistent interpretation of how to test for conformance with accessibility requirements like WCAG \citep{Fiers2019}. The format describes both manual and automated tests. The aim of this is to make accessibility tests transparent and results reproducible.

For example, accessibility testing tools check if the provided HTML meets the requirements defined in WCAG. These requirements are different for each element, but they might be also combined and include more criteria. Each element needs a specific set of requirements to be checked.

ACT Rules include atomic rules that define an element to be tested for a single condition and composite rules that can combine multiple atomic rules to determine if a single test subject satisfies an accessibility requirement \citep{Fiers2019}. Each rule defines when it should be applied. For atomic rules this could be an HTML tag name, computed role or distance between two elements for example and composite rules it is a union of the applicability of the atomic elements it combines.

\subsection{Accessibility evaluation}

% Peter Drucker - an influential thinker on management said: "If you can't measure it you can't improve it".

Different evaluation methods are used to determine if a website is accessible. These include expert review, user testing, subjective assessment, screening techniques or barrier walkthrough. Each method has its pros and cons depending on the subject of the evaluation, available experts and other factors.

Expert review, also called, conformance, standards or guidelines review or manual inspection is most widely used \citep{Brajnik2008}. It means checking if a page satisfies a checklist of criteria. The results depend on the evaluators opinions and depend on the chosen guidelines. Skillful evaluators are needed for this method to be effective. 

Barrier walkthrough is a technique where the evaluator has to assess how seriously some predefined barriers impact the user to achieve their goal on the website \citep{Brajnik2008}. Accessibility barriers can be any condition that makes it difficult for people to achieve a goal. Which method is suitable depends on several factors including the availability of skilled auditors and resources.

Screening techniques consist of evaluating a website by using an interface in a way that some sensory, motor or cognitive capabilities of the user are artificially reduced \citep{Brajnik2008}. Subjective assessment is based on a panel of users exploring a website themselves and giving feedback on what worked and what did not. User testing means conducting usability tests with disabled people while adopting a think-aloud method to get feedback on their experience. 

Evaluations with experts are very dependent on the knowledge and experience of the evaluators. Research into the effect of expertise on web accessibility evaluation conducted by \citeauthor{Brajnik2011} shows that when web pages are evaluated with non-experts we see a drop in reliability and validity \citep{Brajnik2011}. Even with experts, the result will vary a bit, but the results should even out when at least 3 experts are used. For the same level of reliability, at least 14 evaluators that are not considered experts in the field of web accessibility are needed.

\subsubsection{Tools for accessibility testing}

There are software programs and online services that help determine if web content meets accessibility guidelines. These tools may support various standards. They might be browser or authoring tool plugins, command line tools, code linters, open source application programming interfaces (API), desktop or mobile applications or online services \citep{AbouZahra2017}. Some tools are aimed at non-technical content creators and these are often built into the tools they use daily. Others are online services, where you can enter the URL of your website to be evaluated or services that regularly check your website and that is be hosted by the provider or in a company's internal network. 

The results can be presented as a report in HTML, CVS, PDF, XML or other formats, as in-page feedback with temporary icons and markup or as a step-by-step evaluation where the user is prompted to assess the parts that can't be automated \citep{AbouZahra2017}. The tool might transform the page, show only text or take away all the colors, to help identify issues. The scope of what the tool evaluates at once might be a single page or a group of related pages. Some are capable of accessing password-protected content. 

Browser extensions and online tools usually evaluate one page at a time. This might work well for small websites and one-time audits but can be quite ineffective to use as a continuous long-term solution. Command-line interface (CLI) tools need more setup, but can potentially be seamlessly integrated into the development workflow.

Authoring tool plugins could be plugins that check if the color contrast conforms with WCAG requirements in Figma or plugins for integrated development environments (IDE) that provide immediate feedback to a developer in their working environment when they miss something related to accessibility in their code.

Some tools do a very specific task or work inside a very certain tool and ones that try to tackle accessibility as thoroughly as possible. In most cases using many different tools in combination will give you the best result.

\subsubsection{Automated accessibility testing}

In this thesis, a computer program that can be set up to perform checks automatically with minimal manual effort will be called automated accessibility testing. It is important to differentiate these kinds of tools from the wide range of other tools describes in the previous chapter. This would leave out browser extensions because these would need to take extra steps to run the checks every time. Automated tests should be triggered each time a change has been made. The earlier in the development process it can be triggered the better.

Mostly these are CLI tools that can be integrated to run together with other tests. The Document Object Model (DOM) is the data representation of the objects that comprise the structure and content of a document on the web \citep{MDN2023}. These programs scan the rendered DOM of a website against accessibility standards like WCAG to find violations. These errors are reported back with a reference to the code that produced the error.

Continuous integration (CI) is a software development practice where members of the team integrate their work frequently and each integration is verified with an automated build that includes tests to detect errors as quickly as possible \citep{Fowler2006}. This is believed to help develop high-quality software more rapidly. One of the practices in CI is making your code Self-Testing - adding a suite of automated tests that can check a large part of the code base for bugs. These tests need to be easy to trigger and indicate any failures.

This last principle could be applied well to accessibility evaluation. The practice would follow modern software development principles. Tests will not catch everything, but they will catch enough to make it worthwhile. After the initial setup, they should not need a lot of maintenance and will be run every time someone contributes to the codebase. This can act as a very effective gatekeeper for any potential accessibility issues.

According to the survey conducted by Level Access about the state of digital accessibility 67\% of organizations that practice continuous integration also include accessibility tests \citep{LevelAccess}. This has gone up from 56\% reported in 2021. Organizations that have an accessibility program that is in the early stages (2-6 years) or who have IAAP-certified personnel are more likely than average to have implemented a CI testing process that includes accessibility.

It is important to mention that these kinds of tests can detect only a part of all the possible violations. The UK Government Digital Service Accessibility team compared 13 automated tools' performance in \citeyear{GAT2018} on a page that had 142 deliberately introduced accessibility issues and found that they found 13-40\% of issues. \citeauthor{Abbott2021} compared the two most popular accessibility tools that can be used in CI using the same deliberately inaccessible site in \citeyear{Abbott2021} and reported that axe-core caught 27\% and pa11y 20\% \citep{Abbott2021}. \citeauthor{Vigo2013} compared 6 different tools in \citeyear{Vigo2013} and found that they found 23-50\% of  WCAG 2.0 Success Criteria \citep{GAT2018, Abbott2021, Vigo2013}. 

The tools and WCAG standards have evolved during this time, but the common conclusion to most of the similar comparisons is still that most tools will be able to detect errors on 20-30\% or WCAG Success Criteria. \todo{Find citation}

Axe-core accessibility testing engine promises to find on average 57\% issues, which is significantly higher than other tools on the market\citep{Deque2023}. They claim that the current statistics are founded on an inaccurate definition of accessibility coverage - the percentage of individual WCAG Success Criteria. In reality, some types of issues are found much more frequently and the issues found by automated tests form a higher percentage of all issues compared to those discovered by manual detection. They suggest that the coverage should be the percentage of all the issues found on a site. They conducted a study where they compared 2000 audit results from testing pages with axe-core and manual testing methodology. The average percentage of the number of issues detected by axe-core for each data set is 57.38\%.

They also say that looking at the results with current, in their opinion, inaccurate, definition coverage would be in the range of 20-30\% \citep{DequeSystems2021report}. I did not find any studies about other tools that would use the same method for calculating the coverage so for this paper we will still compare the tools according to the most widely used coverage calculation method.

There is still a limit to what can be detected no matter how we define the coverage. More testing will always be required to ensure that the content is fully accessible. The main strength of these kinds of tests is that they can be set up to run automatically, and they provide measurable results. This means it is a good way to monitor compliance with WCAG rules consistently without much extra effort. This can help avoid unwanted changes and show easy fixes in your code.

% WCAG 2.0 was made in a way that works better for automated testing. \todo{Find citation}

\end{document}