% !TeX root = thesis.tex
\documentclass{master_thesis}
\addbibresource{refs.bib}

\begin{document}

\subsection{Web accessibility}

Accessibility is about providing equal access to goods and services to everyone regardless of age, gender, knowledge or disabilities. We all have different abilities, some run faster than others, some see more clearly and some might not be able to hear sounds. A report published by the European Commission in \citeyear{Grammenos2020} estimates that about 7\% of people aged 16 and over who live in the European Union have a strong disability and about 17.5\% a moderate disability \citep{Grammenos2020}. This number gets significantly higher when people get older. Disability prevalence among people aged 65 and over is about 47.8\%.  Disability is a part of being human and persons with disabilities have very different needs. We can also talk about temporary disability - this might be a mother who can only use one hand because she is holding a child in the other or someone who broke an arm and can't use it until it heals. The experiences during a temporary disability may be very similar to a permanent condition. Everyone who designs the physical and virtual environment around us should consider these different limitations.

Accessibility principles can be applied to various fields. For example, in architecture, it could be designing buildings in a way that can be accessed by people who can walk as well as the ones who need to use a wheelchair. In digital products, it is more often related to the senses we use to consume content and navigate. Everything should be equally accessible regardless of the sense someone wants or need to use for consuming the information.

The biggest strength of the web lies in its availability to everyone. Tim Berners-Lee, \ac{wcag} Director and inventor of the World Wide Web said: "The power of the Web is in its universality. Access by everyone regardless of disability is an essential aspect" \citep{WWWC1997}. The virtual world has the potential to be much more inclusive than the physical world.

Web accessibility considers auditory, cognitive, neurological, physical, speech and visual disabilities - everything that might affect someone's ability to access the Web and people using different devices, who have reduced abilities because of aging, temporary disabilities, situational limitations or are using limited or slow internet \citep{Henry2022}.

\subsubsection{Standards}

The standards for considering people with different abilities and making web content accessible for different ways of consuming are defined in \ac{wcag} \citep{Kirkpatrick2018}. The guidelines are developed by \ac{wai} which is part of \ac{w3c}.

The first version of \ac{wcag} (1.0) was published in 1998 \citep{Vanderheiden1998}. The current version is \ac{wcag} 2.1 and the next version 2.2 is scheduled to be finalized in May 2023 \citep{Henry2023}. All \ac{wcag} versions are backward compatible, meaning that all requirements that were in 2.0 are included in 2.1 and some new requirements are added. Version 2.2 is currently in the draft stage, but the planned changes also include some minor changes to the current guidelines.

\ac{wai} gives an overview of the laws and policies around the world. 25 out of 40 listed on the page are based on \ac{wcag} 2.0 or \ac{wcag} 2.0 derivative \citep{Mueller2018}. Pipedrive operates in the US and European markets so the most notable and relevant ones for me are the accessibility standard in European Union EN 301 549 enforced by Web and Mobile Accessibility Directive \citep{MuellerEU2017} and Section 508 of the US Rehabilitation Act of 1973, as amended in the United States \citep{MuellerUS2017}. \ac{wcag} 2.0 AA level conformance has been incorporated into the law in the US and the European standards' latest version follows \ac{wcag} 2.1 AA \citep{LevelAccess2021}. In this thesis, I will test against \ac{wcag} 2.1, because it is the latest published version of the most widely used standard.

\todo{What would be a better resource for this overview? This seems to be outdated because another resource said the EU standard is referencing \ac{wcag} 2.1}

\ac{wcag} is intended for developers of web content, authoring tools or web accessibility evaluation tools and others who need a standard for accessibility \citep{Henry2023}. The 4 principles of accessibility addressed in the guidelines are:
\begin{enumerate}
	\item Perceivable - information and user interface should be presented in a way that users don't have to rely on a single sense to perceive it.
	\item Operable - user can interact with the interface,
	\item Understandable - user should understand the information and how the user interface operates
	\item Robust - content should be robust enough that it can be interpreted reliably by a wide variety of user agents and assistive technology.
\end{enumerate}
Under each principle is a list of guidelines that address that principle \citep{AGWGWP2022}. Under each guideline, there are Success Criteria that describe specifically what conformance to it means. Each Success Criterion is a statement that will be either true or false for specific Web content.

\subsubsection{Rules format}

\ac{w3c} Accessibility Guidelines Working Group has developed \ac{act} Rules Format to provide developers of evaluation methodologies and testing tools a consistent interpretation of how to test for conformance with accessibility requirements like \ac{wcag} \citep{Fiers2019}. The format describes both manual and automated tests. The aim of this is to make accessibility tests transparent and results reproducible.

For example, accessibility testing tools check if the provided \ac{html} meets the requirements defined in \ac{wcag}. These requirements are different for each element, but they might be also combined and include more criteria. Each element needs a specific set of requirements to be checked.

\ac{act} Rules include atomic rules that define an element to be tested for a single condition and composite rules that can combine multiple atomic rules to determine if a single test subject satisfies an accessibility requirement \citep{Fiers2019}. Each rule defines when it should be applied. For atomic rules, this could be an \ac{html} tag name, computed role or distance between two elements for example and composite rules it is a union of the applicability of the atomic elements it combines.

\subsection{Accessibility evaluation}

% Peter Drucker - an influential thinker on management said: "If you can't measure it you can't improve it".

Different evaluation methods are used to determine if a website or mobile application is accessible. These include expert review, user testing, subjective assessment, screening techniques or barrier walkthrough. Each method has its pros and cons depending on the subject of the evaluation, available experts and other factors.

Expert review, also called, conformance, standards or guidelines review or manual inspection is most widely used \citep{Brajnik2008}. It means checking if a page satisfies a checklist of criteria. The results depend on the evaluator's opinions and depend on the chosen guidelines. Skillful evaluators are needed for this method to be effective.

Barrier walkthrough is a technique where the evaluator has to assess how seriously some predefined barriers impact the user to achieve their goal on the website \citep{Brajnik2008}. An Accessibility barrier can be any condition that makes it difficult for people to achieve a goal.

Screening techniques consist of evaluating a website by using the interface while some sensory, motor or cognitive capabilities of the user are artificially reduced \citep{Brajnik2008}. Subjective assessment is based on a panel of users exploring a website themselves and giving feedback on what worked and what did not. User testing means conducting usability tests with disabled people while adopting a think-aloud method to get feedback on their experience.

Which method is suitable depends on several factors including the availability of skilled auditors and other resources. Evaluations with experts are very dependent on the knowledge and experience of the evaluators. Research into the effect of expertise on web accessibility evaluation conducted by \citeauthor{Brajnik2011} shows that when web pages are evaluated with non-experts we see a drop in reliability and validity \citep{Brajnik2011}. Even with experts, the result will vary a bit, but the results should even out when at least 3 experts are used. For the same level of reliability, at least 14 evaluators that are not considered experts in the field of web accessibility are needed.

\review{Mari-Ell: Here I would add the passage about how manual testing is essential as not all the WCAG criteria is machine-testable - some of the criteria is subjective and needs human opinion. Today there are no tools that can interpret if the image's text alternative really conveys its meaning or if the error message of the input field is clear enough.
}

\subsubsection{Tools for accessibility testing}

There are software programs and online services that help determine if web content meets accessibility guidelines. These tools may support various standards. They might be browser or authoring tool plugins, command line tools, code linters, open source \ac{api}, desktop or mobile applications or online services \citep{AbouZahra2017}. Some tools are aimed at non-technical content creators and these are often built into the tools they use daily. Others are online services, where you can enter the URL of your website to be evaluated or services that regularly check your website and that are hosted by the provider or in a company's internal network.

The results can be presented as a report in HTML, CVS, PDF, XML or other formats, as in-page feedback with temporary icons and markup or as a step-by-step evaluation where the user is prompted to assess the parts that can't be automated \citep{AbouZahra2017}. The tool might transform the page, show only text or take away all the colors, to help identify issues. The tools can evaluate either a single page or a group or related pages at the same time. Some tools are even capable of accessing password-protected content.

Browser extensions and online tools usually evaluate one page at a time. This might work well for small websites and one-time audits but can be quite ineffective to use as a continuous long-term solution. \Ac{cli} tools need more setup, but can potentially be seamlessly integrated into the development workflow.

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.4\textwidth}
		\includegraphics[width=\textwidth]{img/figma plugin-color-contrast-fail.png}
		\caption{Color contrast test failing}
	\end{subfigure}
	\begin{subfigure}{0.4\textwidth}
		\includegraphics[width=\textwidth]{img/figma plugin-color-contrast-pass.png}
		\caption{Color contrast test passing}
	\end{subfigure}
\caption{Figma plugin for testing color contrast compliance with \ac{wcag}}
\label{fig:figma-plugin}
\end{figure}

Authoring tool plugins for Figma that check if the colors used in the design conform with \ac{wcag} requirements (see Figure \ref{fig:figma-plugin}) or plugins for integrated development environments that provide immediate feedback to a developer in their working environment when they miss something related to accessibility in their code.

Some tools do a very specific task or work inside a very certain tool and others try to tackle accessibility as thoroughly as possible. In most cases, using many different tools in combination will give the best result.

\subsubsection{Continious accessibility testing}

\Ac{ci} is a software development practice where members of the team integrate their work frequently and each integration is verified with an automated build that includes tests to detect errors as quickly as possible \citep{Fowler2006}. This is believed to help develop high-quality software more rapidly. One of the practices in \ac{ci} is making your code Self-Testing - adding a suite of automated tests that can check a large part of the codebase for bugs. These tests need to be easy to trigger and indicate any failures.

This last principle could be applied well to accessibility evaluation. This practice would follow modern software development principles. The automated tests will not catch everything, but they will catch enough to make it worthwhile. After the initial setup, they should not need a lot of maintenance and will be run every time someone contributes to the codebase. This can act as a very effective gatekeeper for any potential accessibility issues.

Tools that can be set up to perform checks every time changes have been made automatically with minimal manual effort can be used for continuous accessibility testing. The earlier in the development process these can be triggered, the better. Not all of the tools described in the previous chapter can be used for that. Browser extensions and plugins in authoring tools need to be manually triggered to perform checks.

\ac{cli} based tools are most suitable for this purpose. They can be customized to specific needs and integrated to run together with other tests. The \ac{dom} is the data representation of the objects that comprise the structure and content of a document on the web \citep{MDN2023}. These programs scan the rendered \ac{dom} of a website against accessibility standards like \ac{wcag} to find violations. These errors are reported back with a reference to the code that produced the error.

According to the survey conducted by Level Access about the state of digital accessibility 67\% of organizations that practice \ac{ci} also include accessibility tests \citep{LevelAccess}. This has gone up from 56\% reported in 2021. 91\% of all organizations that participated in the survey say they use accessibility testing tools and most of them prefer the free options available. Browser extensions are by far the most popular tool with 82.4\% of organizations using them. 23.4\% has reported that they use testing technology that integrates with their \ac{ci} tool and 22.7\% uses testing technology that is compatible with their test framework. Organizations that have an accessibility program in its early stages (2-6 years) or have \ac{iaap}-certified personnel are more likely than the average to have implemented a \ac{ci} testing process.

It is important to mention that automated tests can detect only a part of all the possible violations. The UK Government Digital Service Accessibility team compared 13 automated tools' performance in \citeyear{GAT2018} on a page that had 142 deliberately introduced accessibility issues and found the automated tools were able to detect 13-40\% of issues. \citeauthor{Abbott2021} compared the two most popular accessibility tools that can be used in \ac{ci} using the same deliberately inaccessible site in \citeyear{Abbott2021} and reported that axe-core caught 27\% and pa11y 20\% \citep{Abbott2021}. \citeauthor{Vigo2013} compared 6 different tools in \citeyear{Vigo2013} and found that they were able to detect 23-50\% of  \ac{wcag} 2.0 Success Criteria \citep{GAT2018, Abbott2021, Vigo2013}.

The tools and \ac{wcag} standards have evolved during this time, but the common conclusion to most of the similar comparisons is still that most tools will be able to detect errors on 20-30\% or \ac{wcag} Success Criteria. \todo{Find citation}

Axe-core accessibility testing engine promises to find on average 57\% issues, which is significantly higher than other tools on the market \citep{Deque2023}. They claim that the current statistics are founded on an inaccurate definition of accessibility coverage - the percentage of individual \ac{wcag} Success Criteria. In reality, some types of issues are found much more frequently and the issues found by automated tests form a higher percentage of all issues compared to those discovered by manual detection. They suggest that the coverage should be the percentage of all the issues found on a site. They conducted a study where they compared 2000 audit results from testing pages with axe-core and manual testing methodology. The average percentage of the number of issues detected by axe-core for each data set is 57.38\%.

They also say that looking at the results with current, in their opinion, inaccurate, definition of coverage would be in the range of 20-30\% \citep{DequeSystems2021report}. I did not find any studies about other tools that would use the same method for calculating the coverage so for this paper we will still compare the tools according to the most widely used coverage calculation method.

There is still a limit to what can be detected no matter how we define the coverage.
\review{Mari-Ell: Add something here about the fact that it is not that the tools are BAD, they just cannot interpret things that need human opinion. However, many things that in my opinion could be tested with tools, for some reason, cannot - image alt texts that are just "object" or "image" are usually nor marked as error, and icons and input fields that are almost invisible, are also not marked as errors.}
Manual testing will always be required to ensure that the content is fully accessible. The main strength of automated tests is that they can be set up to run automatically, and they provide measurable results. Therefore, it is a good way to monitor compliance with \ac{wcag} rules consistently without much extra effort. This can help avoid unwanted changes and highlight issues in code that should be straightforward to fix.

\end{document}